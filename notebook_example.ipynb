{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Benthic Megafauna using a CNN\n",
    "\n",
    "Before you can use this notebook, make sure that you have downloaded the basml.py (python) file and put it into your working directory. Also, make sure that you have all of the required libraries installed; libraries can be installed using:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can git clone the whole repository https://github.com/brett-hosking/BASML_DataChallenge.git\n",
    "\n",
    "See https://github.com/brett-hosking/BASML_DataChallenge for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the data: \n",
    "'https://github.com/brett-hosking/BASML_DataChallenge/blob/master/data256.zip?raw=true'\n",
    "\n",
    "Download basml.py file:\n",
    "'https://github.com/brett-hosking/BASML_DataChallenge/blob/master/basml.py?raw=true'\n",
    "\n",
    "Download requirements.txt file:\n",
    "'https://github.com/brett-hosking/BASML_DataChallenge/blob/master/requirements.txt?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "import basml # some pre-made functions for this data challenge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data using pre-made function in the basml mini library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (2094, 256, 256, 3)\n",
      "labels: (2094, 4)\n"
     ]
    }
   ],
   "source": [
    "X,Y = basml.loaddata('data256') # the folder containing the downloaded data for this challenege\n",
    "print('data:', np.shape(X))\n",
    "print('labels:', np.shape(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalise the values, in range [0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random training and test. Here we use 80% of the data for training and 20% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = basml.randomiseXY(X,Y)\n",
    "Xtrain,Ytrain,Xtest,Ytest = basml.ttsplit(X,Y,per=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1675, 256, 256, 3) (1675, 4) (419, 256, 256, 3) (419, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Xtrain),np.shape(Ytrain), np.shape(Xtest), np.shape(Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply zeromean normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeromean = np.mean(Xtrain)\n",
    "Xtrain -=zeromean\n",
    "Xtest -=zeromean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wilski/venv/basml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CNN using the training data (using the validation_data hyperparameter is optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1675 samples, validate on 419 samples\n",
      "Epoch 1/5\n",
      "1675/1675 [==============================] - 247s 148ms/sample - loss: 0.6118 - acc: 0.8496 - val_loss: 0.7657 - val_acc: 0.7494\n",
      "Epoch 2/5\n",
      "1675/1675 [==============================] - 287s 171ms/sample - loss: 0.4534 - acc: 0.8854 - val_loss: 0.5352 - val_acc: 0.8473\n",
      "Epoch 3/5\n",
      "1675/1675 [==============================] - 397s 237ms/sample - loss: 0.3280 - acc: 0.9296 - val_loss: 0.4009 - val_acc: 0.8998\n",
      "Epoch 4/5\n",
      "1675/1675 [==============================] - 244s 146ms/sample - loss: 0.1914 - acc: 0.9504 - val_loss: 0.4469 - val_acc: 0.8783\n",
      "Epoch 5/5\n",
      "1675/1675 [==============================] - 247s 148ms/sample - loss: 0.1800 - acc: 0.9606 - val_loss: 0.4781 - val_acc: 0.8902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10640f4a8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, epochs=5,validation_data=(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to predict the class of samples in the test set and reformat as one-hot, e.g. [0,1,0,0] for the second class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlen = len(Ytest)\n",
    "Ypred= np.array(np.zeros((testlen,4)))\n",
    "predictions = model.predict(Xtest)\n",
    "for i in range(testlen):\n",
    "    Ypred[i][np.argmax(predictions[i])] \t= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn to generate a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       101\n",
      "           1       0.86      0.93      0.89       104\n",
      "           2       0.98      0.77      0.86       113\n",
      "           3       0.81      0.91      0.86       101\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       419\n",
      "   macro avg       0.90      0.89      0.89       419\n",
      "weighted avg       0.90      0.89      0.89       419\n",
      " samples avg       0.89      0.89      0.89       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Ytest, Ypred)#, target_names=class_list,digits=6,labels=range(classes))\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
